{
	"jobConfig": {
		"name": "Inferencia",
		"description": "",
		"role": "arn:aws:iam::096941180198:role/jmmarinq",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "Inferencia.py",
		"scriptLocation": "s3://aws-glue-assets-096941180198-us-east-1/scripts/",
		"language": "python-3",
		"spark": false,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-05-21T02:31:43.578Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-096941180198-us-east-1/temporary/",
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-096941180198-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.types import BooleanType\r\nfrom pyspark.ml.feature import Tokenizer\r\n\r\nsc = SparkContext.getOrCreate()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\nlogger = glueContext.get_logger()\r\n\r\noutput_path_predictions = \"s3://nequijmmarinq/predictions/\"\r\nmodel_output_path = \"s3://nequijmmarinq/models/msg-classifier\"\r\ntest_path = \"s3://nequijmmarinq/test/\"\r\n\r\ntry:\r\n    from pyspark.ml import PipelineModel\r\n    logger.info(\"Cargando modelo desde S3...\")\r\n    model = PipelineModel.load(model_output_path)\r\n    logger.info(\"Realizando inferencia en batch...\")\r\n    df = spark.read.parquet(test_path)\r\n    predictions = model.transform(df)\r\n    predictions.select(\"text\", \"prediction\").write.mode(\"overwrite\").parquet(output_path_predictions)\r\n\r\n    logger.info(\"Inferencia completada y resultados guardados.\")\r\n\r\nexcept Exception as e:\r\n    logger.warn(f\"Modelo no encontrado o error en inferencia: {str(e)}\")\r\n\r\nlogger.info(\"Pipeline completo.\")\r\n"
}