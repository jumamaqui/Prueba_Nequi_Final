{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		},
		"toc-autonumbering": true
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "#librerias\nimport sys\nfrom awsglue.context import GlueContext\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import BooleanType, TimestampType, IntegerType\nfrom pyspark.ml.feature import Tokenizer\nimport pyspark.pandas as ps\nimport string\nimport boto3\nimport os\nfrom collections import Counter\nimport re\nfrom awsglue.job import Job",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Crear conexiones\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\nlogger = glueContext.get_logger()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 29,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Parametros y Funciones\ns3_client = boto3.client('s3')\nbucket_name = 'nequijmmarinq'\nfile_key = 'stopwords'\ninput_path = 's3://nequijmmarinq/twcs.csv'\noutput_path_clean = \"s3://nequijmmarinq/processed/clean_data/\"\n\nPUNCT_TO_REMOVE = string.punctuation\nEMOTICONS = {\n    u\":‚Äë\\)\":\"Happy face or smiley\",\n    u\":\\)\":\"Happy face or smiley\",\n    u\":-\\]\":\"Happy face or smiley\",\n    u\":\\]\":\"Happy face or smiley\",\n    u\":-3\":\"Happy face smiley\",\n    u\":3\":\"Happy face smiley\",\n    u\":->\":\"Happy face smiley\",\n    u\":>\":\"Happy face smiley\",\n    u\"8-\\)\":\"Happy face smiley\",\n    u\":o\\)\":\"Happy face smiley\",\n    u\":-\\}\":\"Happy face smiley\",\n    u\":\\}\":\"Happy face smiley\",\n    u\":-\\)\":\"Happy face smiley\",\n    u\":c\\)\":\"Happy face smiley\",\n    u\":\\^\\)\":\"Happy face smiley\",\n    u\"=\\]\":\"Happy face smiley\",\n    u\"=\\)\":\"Happy face smiley\",\n    u\":‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\":D\":\"Laughing, big grin or laugh with glasses\",\n    u\"8‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n    u\"X‚ÄëD\":\"Laughing, big grin or laugh with glasses\",\n    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n    u\":-\\)\\)\":\"Very happy\",\n    u\":‚Äë\\(\":\"Frown, sad, andry or pouting\",\n    u\":-\\(\":\"Frown, sad, andry or pouting\",\n    u\":\\(\":\"Frown, sad, andry or pouting\",\n    u\":‚Äëc\":\"Frown, sad, andry or pouting\",\n    u\":c\":\"Frown, sad, andry or pouting\",\n    u\":‚Äë<\":\"Frown, sad, andry or pouting\",\n    u\":<\":\"Frown, sad, andry or pouting\",\n    u\":‚Äë\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\[\":\"Frown, sad, andry or pouting\",\n    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n    u\">:\\[\":\"Frown, sad, andry or pouting\",\n    u\":\\{\":\"Frown, sad, andry or pouting\",\n    u\":@\":\"Frown, sad, andry or pouting\",\n    u\">:\\(\":\"Frown, sad, andry or pouting\",\n    u\":'‚Äë\\(\":\"Crying\",\n    u\":'\\(\":\"Crying\",\n    u\":'‚Äë\\)\":\"Tears of happiness\",\n    u\":'\\)\":\"Tears of happiness\",\n    u\"D‚Äë':\":\"Horror\",\n    u\"D:<\":\"Disgust\",\n    u\"D:\":\"Sadness\",\n    u\"D8\":\"Great dismay\",\n    u\"D;\":\"Great dismay\",\n    u\"D=\":\"Great dismay\",\n    u\"DX\":\"Great dismay\",\n    u\":‚ÄëO\":\"Surprise\",\n    u\":O\":\"Surprise\",\n    u\":‚Äëo\":\"Surprise\",\n    u\":o\":\"Surprise\",\n    u\":-0\":\"Shock\",\n    u\"8‚Äë0\":\"Yawn\",\n    u\">:O\":\"Yawn\",\n    u\":-\\*\":\"Kiss\",\n    u\":\\*\":\"Kiss\",\n    u\":X\":\"Kiss\",\n    u\";‚Äë\\)\":\"Wink or smirk\",\n    u\";\\)\":\"Wink or smirk\",\n    u\"\\*-\\)\":\"Wink or smirk\",\n    u\"\\*\\)\":\"Wink or smirk\",\n    u\";‚Äë\\]\":\"Wink or smirk\",\n    u\";\\]\":\"Wink or smirk\",\n    u\";\\^\\)\":\"Wink or smirk\",\n    u\":‚Äë,\":\"Wink or smirk\",\n    u\";D\":\"Wink or smirk\",\n    u\":‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"X‚ÄëP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‚Äë√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":√û\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\":‚Äë/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n    u\":‚Äë\\|\":\"Straight face\",\n    u\":\\|\":\"Straight face\",\n    u\":$\":\"Embarrassed or blushing\",\n    u\":‚Äëx\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‚Äë#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":‚Äë&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n    u\"O:‚Äë\\)\":\"Angel, saint or innocent\",\n    u\"O:\\)\":\"Angel, saint or innocent\",\n    u\"0:‚Äë3\":\"Angel, saint or innocent\",\n    u\"0:3\":\"Angel, saint or innocent\",\n    u\"0:‚Äë\\)\":\"Angel, saint or innocent\",\n    u\"0:\\)\":\"Angel, saint or innocent\",\n    u\":‚Äëb\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n    u\">:‚Äë\\)\":\"Evil or devilish\",\n    u\">:\\)\":\"Evil or devilish\",\n    u\"\\}:‚Äë\\)\":\"Evil or devilish\",\n    u\"\\}:\\)\":\"Evil or devilish\",\n    u\"3:‚Äë\\)\":\"Evil or devilish\",\n    u\"3:\\)\":\"Evil or devilish\",\n    u\">;\\)\":\"Evil or devilish\",\n    u\"\\|;‚Äë\\)\":\"Cool\",\n    u\"\\|‚ÄëO\":\"Bored\",\n    u\":‚ÄëJ\":\"Tongue-in-cheek\",\n    u\"#‚Äë\\)\":\"Party all night\",\n    u\"%‚Äë\\)\":\"Drunk or confused\",\n    u\"%\\)\":\"Drunk or confused\",\n    u\":-###..\":\"Being sick\",\n    u\":###..\":\"Being sick\",\n    u\"<:‚Äë\\|\":\"Dump\",\n    u\"\\(>_<\\)\":\"Troubled\",\n    u\"\\(>_<\\)>\":\"Troubled\",\n    u\"\\(';'\\)\":\"Baby\",\n    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(~_~;\\) \\(„Éª\\.„Éª;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n    u\"\\(-_-\\)zzz\":\"Sleeping\",\n    u\"\\(\\^_-\\)\":\"Wink\",\n    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n    u\"\\(\\+o\\+\\)\":\"Confused\",\n    u\"\\(o\\|o\\)\":\"Ultraman\",\n    u\"\\^_\\^\":\"Joyful\",\n    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n    u\"\\(\\^O\\^\\)Ôºè\":\"Joyful\",\n    u\"\\(\\^o\\^\\)Ôºè\":\"Joyful\",\n    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n    u\"\\('_'\\)\":\"Sad or Crying\",\n    u\"\\(/_;\\)\":\"Sad or Crying\",\n    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n    u\"\\(;_;\":\"Sad of Crying\",\n    u\"\\(;_:\\)\":\"Sad or Crying\",\n    u\"\\(;O;\\)\":\"Sad or Crying\",\n    u\"\\(:_;\\)\":\"Sad or Crying\",\n    u\"\\(ToT\\)\":\"Sad or Crying\",\n    u\";_;\":\"Sad or Crying\",\n    u\";-;\":\"Sad or Crying\",\n    u\";n;\":\"Sad or Crying\",\n    u\";;\":\"Sad or Crying\",\n    u\"Q\\.Q\":\"Sad or Crying\",\n    u\"T\\.T\":\"Sad or Crying\",\n    u\"QQ\":\"Sad or Crying\",\n    u\"Q_Q\":\"Sad or Crying\",\n    u\"\\(-\\.-\\)\":\"Shame\",\n    u\"\\(-_-\\)\":\"Shame\",\n    u\"\\(‰∏Ä‰∏Ä\\)\":\"Shame\",\n    u\"\\(Ôºõ‰∏Ä_‰∏Ä\\)\":\"Shame\",\n    u\"\\(=_=\\)\":\"Tired\",\n    u\"\\(=\\^\\¬∑\\^=\\)\":\"cat\",\n    u\"\\(=\\^\\¬∑\\¬∑\\^=\\)\":\"cat\",\n    u\"=_\\^=\t\":\"cat\",\n    u\"\\(\\.\\.\\)\":\"Looking down\",\n    u\"\\(\\._\\.\\)\":\"Looking down\",\n    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n    u\"\\(\\„Éª\\„Éª?\":\"Confusion\",\n    u\"\\(?_?\\)\":\"Confusion\",\n    u\">\\^_\\^<\":\"Normal Laugh\",\n    u\"<\\^!\\^>\":\"Normal Laugh\",\n    u\"\\^/\\^\":\"Normal Laugh\",\n    u\"\\Ôºà\\*\\^_\\^\\*Ôºâ\" :\"Normal Laugh\",\n    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n    u\"\\(\\^‚Äî\\^\\Ôºâ\":\"Normal Laugh\",\n    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n    u\"\\Ôºà\\^‚Äî\\^\\Ôºâ\":\"Waving\",\n    u\"\\(;_;\\)/~~~\":\"Waving\",\n    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n    u\"\\(-_-\\)/~~~ \\($\\¬∑\\¬∑\\)/~~~\":\"Waving\",\n    u\"\\(T_T\\)/~~~\":\"Waving\",\n    u\"\\(ToT\\)/~~~\":\"Waving\",\n    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n    u\"\\(\\*_\\*\\)\":\"Amazed\",\n    u\"\\(\\*_\\*;\":\"Amazed\",\n    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n    u'\\(-\"-\\)':\"Worried\",\n    u\"\\(„Éº„Éº;\\)\":\"Worried\",\n    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n    u\"\\(\\ÔºæÔΩñ\\Ôºæ\\)\":\"Happy\",\n    u\"\\(\\ÔºæÔΩï\\Ôºæ\\)\":\"Happy\",\n    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n    u\"\\(\\^O\\^\\)\":\"Happy\",\n    u\"\\(\\^o\\^\\)\":\"Happy\",\n    u\"\\)\\^o\\^\\(\":\"Happy\",\n    u\":O o_O\":\"Surprised\",\n    u\"o_0\":\"Surprised\",\n    u\"o\\.O\":\"Surpised\",\n    u\"\\(o\\.o\\)\":\"Surprised\",\n    u\"oO\":\"Surprised\",\n    u\"\\(\\*Ôø£mÔø£\\)\":\"Dissatisfied\",\n    u\"\\(‚ÄòA`\\)\":\"Snubbed or Deflated\"\n}\n\nchat_words_str = \"\"\"\nAFAIK=As Far As I Know\nAFK=Away From Keyboard\nASAP=As Soon As Possible\nATK=At The Keyboard\nATM=At The Moment\nA3=Anytime, Anywhere, Anyplace\nBAK=Back At Keyboard\nBBL=Be Back Later\nBBS=Be Back Soon\nBFN=Bye For Now\nB4N=Bye For Now\nBRB=Be Right Back\nBRT=Be Right There\nBTW=By The Way\nB4=Before\nB4N=Bye For Now\nCU=See You\nCUL8R=See You Later\nCYA=See You\nFAQ=Frequently Asked Questions\nFC=Fingers Crossed\nFWIW=For What It's Worth\nFYI=For Your Information\nGAL=Get A Life\nGG=Good Game\nGN=Good Night\nGMTA=Great Minds Think Alike\nGR8=Great!\nG9=Genius\nIC=I See\nICQ=I Seek you (also a chat program)\nILU=ILU: I Love You\nIMHO=In My Honest/Humble Opinion\nIMO=In My Opinion\nIOW=In Other Words\nIRL=In Real Life\nKISS=Keep It Simple, Stupid\nLDR=Long Distance Relationship\nLMAO=Laugh My A.. Off\nLOL=Laughing Out Loud\nLTNS=Long Time No See\nL8R=Later\nMTE=My Thoughts Exactly\nM8=Mate\nNRN=No Reply Necessary\nOIC=Oh I See\nPITA=Pain In The A..\nPRT=Party\nPRW=Parents Are Watching\nROFL=Rolling On The Floor Laughing\nROFLOL=Rolling On The Floor Laughing Out Loud\nROTFLMAO=Rolling On The Floor Laughing My A.. Off\nSK8=Skate\nSTATS=Your sex and age\nASL=Age, Sex, Location\nTHX=Thank You\nTTFN=Ta-Ta For Now!\nTTYL=Talk To You Later\nU=You\nU2=You Too\nU4E=Yours For Ever\nWB=Welcome Back\nWTF=What The F...\nWTG=Way To Go!\nWUF=Where Are You From?\nW8=Wait...\n7K=Sick:-D Laugher\n\"\"\"\ndef remove_punctuation(text):\n    text = str(text)\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\ndef remove_stopwords(text):\n    text = str(text)\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\ndef remove_freqwords(text):\n    text = str(text)\n    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n\ndef remove_rarewords(text):\n    text = str(text)\n    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n\ndef remove_emoji(string):\n    text = str(string)\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\n\ndef remove_emoticons(text):\n    text = str(text)\n    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n    return emoticon_pattern.sub(r'', text)\n\ndef remove_urls(text):\n    text = str(text)\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\ndef remove_html(text):\n    text = str(text)\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)\n\ndef chat_words_conversion(text):\n    text = str(text)\n    new_text = []\n    for w in text.split():\n        if w.upper() in chat_words_list:\n            new_text.append(chat_words_map_dict[w.upper()])\n        else:\n            new_text.append(w)\n    return \" \".join(new_text)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Leer el archivo en spark \nlogger.info(\"Leyendo datos desde S3...\")\ndf = spark.read.option(\"header\", True).csv(input_path)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.schema",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 32,
			"outputs": [
				{
					"name": "stdout",
					"text": "StructType([StructField('tweet_id', StringType(), True), StructField('author_id', StringType(), True), StructField('inbound', StringType(), True), StructField('created_at', StringType(), True), StructField('text', StringType(), True), StructField('response_tweet_id', StringType(), True), StructField('in_response_to_tweet_id', StringType(), True)])\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 33,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+------------+-------+--------------------+--------------------+-----------------+-----------------------+\n|tweet_id|   author_id|inbound|          created_at|                text|response_tweet_id|in_response_to_tweet_id|\n+--------+------------+-------+--------------------+--------------------+-----------------+-----------------------+\n|       1|  sprintcare|  False|Tue Oct 31 22:10:...|@115712 I underst...|                2|                      3|\n|       2|      115712|   True|Tue Oct 31 22:11:...|@sprintcare and h...|             null|                      1|\n|       3|      115712|   True|Tue Oct 31 22:08:...|@sprintcare I hav...|                1|                      4|\n|       4|  sprintcare|  False|Tue Oct 31 21:54:...|@115712 Please se...|                3|                      5|\n|       5|      115712|   True|Tue Oct 31 21:49:...|  @sprintcare I did.|                4|                      6|\n|       6|  sprintcare|  False|Tue Oct 31 21:46:...|@115712 Can you p...|              5,7|                      8|\n|       8|      115712|   True|Tue Oct 31 21:45:...|@sprintcare is th...|           9,6,10|                   null|\n|      11|  sprintcare|  False|Tue Oct 31 22:10:...|@115713 This is s...|             null|                     12|\n|      12|      115713|   True|Tue Oct 31 22:04:...|@sprintcare You g...|         11,13,14|                     15|\n|      15|  sprintcare|  False|Tue Oct 31 20:03:...|@115713 We unders...|               12|                     16|\n|      16|      115713|   True|Tue Oct 31 20:00:...|@sprintcare Since...|               15|                     17|\n|      17|  sprintcare|  False|Tue Oct 31 19:59:...|@115713 H there! ...|               16|                     18|\n|      18|      115713|   True|Tue Oct 31 19:56:...|@115714 y‚Äôall lie...|               17|                   null|\n|      19|  sprintcare|  False|Tue Oct 31 22:10:...|@115715 Please se...|             null|                     20|\n|      20|      115715|   True|Tue Oct 31 22:03:...|@115714 whenever ...|               19|                   null|\n|      21|Ask_Spectrum|  False|Tue Oct 31 22:14:...|@115716 What info...|            22,23|                     24|\n|      22|      115716|   True|Tue Oct 31 22:16:...|@Ask_Spectrum Wou...|               25|                     21|\n|      25|Ask_Spectrum|  False|Tue Oct 31 22:18:...|@115716 Our depar...|               26|                     22|\n|      26|      115716|   True|Tue Oct 31 22:19:...|@Ask_Spectrum I r...|               27|                     25|\n|      27|Ask_Spectrum|  False|Tue Oct 31 22:21:...|@115716 No thank ...|             null|                     26|\n+--------+------------+-------+--------------------+--------------------+-----------------+-----------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar registros incompletos y variables innecesarias\nlogger.info(\"Eliminar Registros Incompletos y variables innecesarias...\")\ndf_clean = (\n    df.dropna(subset=[\"text\", \"created_at\"])  # Eliminar registros incompletos\n      .withColumn(\"inbound\", F.col(\"inbound\").cast(BooleanType()))\n      .withColumn(\"inbound\", F.col(\"inbound\").cast(IntegerType()))\n      .drop(\"tweet_id\", \"author_id\", \"response_tweet_id\", \"in_response_to_tweet_id\")  # columnas innecesarias\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 34,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean.schema",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 35,
			"outputs": [
				{
					"name": "stdout",
					"text": "StructType([StructField('inbound', IntegerType(), True), StructField('created_at', StringType(), True), StructField('text', StringType(), True)])\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean.count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 36,
			"outputs": [
				{
					"name": "stdout",
					"text": "2812943\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "logger.info(\"Validaci√≥n de calidad de los datos...\")\nnull_counts = df_clean.select([\n    F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_clean.columns\n])\nnull_counts.show()\n\nlogger.info(f\"Total registros despu√©s de limpieza: {df_clean.count()}\")\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 37,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+----------+----+\n|inbound|created_at|text|\n+-------+----------+----+\n|   1167|         0|   0|\n+-------+----------+----+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 38,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+--------------------+--------------------+\n|inbound|          created_at|                text|\n+-------+--------------------+--------------------+\n|      0|Tue Oct 31 22:10:...|@115712 I underst...|\n|      1|Tue Oct 31 22:11:...|@sprintcare and h...|\n|      1|Tue Oct 31 22:08:...|@sprintcare I hav...|\n|      0|Tue Oct 31 21:54:...|@115712 Please se...|\n|      1|Tue Oct 31 21:49:...|  @sprintcare I did.|\n|      0|Tue Oct 31 21:46:...|@115712 Can you p...|\n|      1|Tue Oct 31 21:45:...|@sprintcare is th...|\n|      0|Tue Oct 31 22:10:...|@115713 This is s...|\n|      1|Tue Oct 31 22:04:...|@sprintcare You g...|\n|      0|Tue Oct 31 20:03:...|@115713 We unders...|\n|      1|Tue Oct 31 20:00:...|@sprintcare Since...|\n|      0|Tue Oct 31 19:59:...|@115713 H there! ...|\n|      1|Tue Oct 31 19:56:...|@115714 y‚Äôall lie...|\n|      0|Tue Oct 31 22:10:...|@115715 Please se...|\n|      1|Tue Oct 31 22:03:...|@115714 whenever ...|\n|      0|Tue Oct 31 22:14:...|@115716 What info...|\n|      1|Tue Oct 31 22:16:...|@Ask_Spectrum Wou...|\n|      0|Tue Oct 31 22:18:...|@115716 Our depar...|\n|      1|Tue Oct 31 22:19:...|@Ask_Spectrum I r...|\n|      0|Tue Oct 31 22:21:...|@115716 No thank ...|\n+-------+--------------------+--------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean = df_clean.dropna(subset=[\"text\", \"created_at\",\"inbound\"])",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 39,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean.count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 40,
			"outputs": [
				{
					"name": "stdout",
					"text": "2811776\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_clean.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+--------------------+--------------------+\n|inbound|          created_at|                text|\n+-------+--------------------+--------------------+\n|  false|Tue Oct 31 22:10:...|@115712 I underst...|\n|   true|Tue Oct 31 22:11:...|@sprintcare and h...|\n|   true|Tue Oct 31 22:08:...|@sprintcare I hav...|\n|  false|Tue Oct 31 21:54:...|@115712 Please se...|\n|   true|Tue Oct 31 21:49:...|  @sprintcare I did.|\n|  false|Tue Oct 31 21:46:...|@115712 Can you p...|\n|   true|Tue Oct 31 21:45:...|@sprintcare is th...|\n|  false|Tue Oct 31 22:10:...|@115713 This is s...|\n|   true|Tue Oct 31 22:04:...|@sprintcare You g...|\n|  false|Tue Oct 31 20:03:...|@115713 We unders...|\n|   true|Tue Oct 31 20:00:...|@sprintcare Since...|\n|  false|Tue Oct 31 19:59:...|@115713 H there! ...|\n|   true|Tue Oct 31 19:56:...|@115714 y‚Äôall lie...|\n|  false|Tue Oct 31 22:10:...|@115715 Please se...|\n|   true|Tue Oct 31 22:03:...|@115714 whenever ...|\n|  false|Tue Oct 31 22:14:...|@115716 What info...|\n|   true|Tue Oct 31 22:16:...|@Ask_Spectrum Wou...|\n|  false|Tue Oct 31 22:18:...|@115716 Our depar...|\n|   true|Tue Oct 31 22:19:...|@Ask_Spectrum I r...|\n|  false|Tue Oct 31 22:21:...|@115716 No thank ...|\n+-------+--------------------+--------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Realizaremos la limpieza en pandas \nlogger.info(\"Iniciando limpieza de datos...\")\ndf_p = ps.DataFrame(df_clean)\n#Aplicar minusculas al texto, ya que disminuye los duplicados\ndf_p[\"text\"] = df_p[\"text\"].str.lower()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Remover puntuacion, ya que disminuye los duplicados\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_punctuation(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Se sube el stopwords a s3, se van a eliminar las stopwords, palabras que no aportan mucho al analisis\ns3_client.download_file(bucket_name, file_key, '/tmp/stopwords.txt')\nwith open('/tmp/stopwords.txt', 'r') as file:\n    stop_words = file.readlines()\nstop_words = [word.strip() for word in stop_words]\nSTOPWORDS = set(stop_words)\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_stopwords(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar las 10 palabras mas frecuentes, ya que no aporta tampoco tanto a la informaci√≥n\ncnt = Counter()\nfor text in df_p[\"text\"].values:\n    for word in text.split():\n        cnt[word] += 1\n        \ncnt.most_common(10)\n        \nFREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_freqwords(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/generic.py:647: UserWarning: We recommend using `Series.to_numpy()` instead.\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: `to_numpy` loads all data into the driver's memory. It should only be used if the resulting NumPy ndarray is expected to be small.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "cnt.most_common(10)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "[('us', 446024), ('please', 395713), ('dm', 332255), ('help', 263310), ('hi', 223666), ('thanks', 202524), ('get', 196690), ('sorry', 191257), ('like', 144306), ('know', 142810)]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar igualmente lo que se conoce como palabras raras o menos frecuentes\nn_rare_words = 10\nRAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_rarewords(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar Emojis, los emojis ya hacen parte de la vida diaria, sin embargo para el modelamiento no aportan mucho\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_emoji(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "remove_emoji(\"game is on üî•üî•\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "'game is on '\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar emoticones, los emoticones ya hacen parte de la vida diaria, sin embargo para el modelamiento no aportan mucho\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_emoticons(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "remove_emoticons(\"Hello :-)\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "'Hello '\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar las urls\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_urls(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "text = \"Driverless AI NLP blog post on https://www.h2o.ai/blog/detecting-sarcasm-is-difficult-but-ai-may-have-an-answer/\"\nremove_urls(text)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "'Driverless AI NLP blog post on '\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Eliminar los tags\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: remove_html(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "text = \"\"\"<div>\n<h1> H2O</h1>\n<p> AutoML</p>\n<a href=\"https://www.h2o.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n</div>\"\"\"\n\nprint(remove_html(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n H2O\n AutoML\n Driverless AI\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#Conversiones de tipificaciones de jerga de la lengua\nchat_words_map_dict = {}\nchat_words_list = []\nfor line in chat_words_str.split(\"\\n\"):\n    if line != \"\":\n        cw = line.split(\"=\")[0]\n        cw_expanded = line.split(\"=\")[1]\n        chat_words_list.append(cw)\n        chat_words_map_dict[cw] = cw_expanded\nchat_words_list = set(chat_words_list)\n\ndf_p[\"text\"] = df_p[\"text\"].apply(lambda text: chat_words_conversion(text))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/pandas/internal.py:1573: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  fields = [\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "chat_words_conversion(\"one minute BRB\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "'one minute Be Right Back'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#logger.info(\"Tokenizando texto...\")\n#tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n#df_clean = tokenizer.transform(df_clean)",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "spark_df.write.mode(\"overwrite\").parquet(output_path_clean)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 45,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}